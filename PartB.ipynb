{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1\n",
    "---\n",
    "Part B, Q1 (15 marks)\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from year 2020 and before as training data, and year 2021 as test data (validation set is not required).\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  year        town              full_address   nearest_stn  \\\n",
      "0      1  2017  ANG MO KIO  406 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
      "1      1  2017  ANG MO KIO   108 ANG MO KIO AVENUE 4    Ang Mo Kio   \n",
      "2      1  2017  ANG MO KIO   602 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
      "3      1  2017  ANG MO KIO  465 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
      "4      1  2017  ANG MO KIO   601 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
      "\n",
      "   dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
      "0             1.007264       7.006044           0.016807   \n",
      "1             1.271389       7.983837           0.016807   \n",
      "2             1.069743       9.090700           0.016807   \n",
      "3             0.946890       7.519889           0.016807   \n",
      "4             1.092551       9.130489           0.016807   \n",
      "\n",
      "   eigenvector_centrality         flat_model_type  remaining_lease_years  \\\n",
      "0                0.006243        2 ROOM, Improved              61.333333   \n",
      "1                0.006243  3 ROOM, New Generation              60.583333   \n",
      "2                0.002459  3 ROOM, New Generation              62.416667   \n",
      "3                0.006243  3 ROOM, New Generation              62.083333   \n",
      "4                0.002459  3 ROOM, New Generation              62.416667   \n",
      "\n",
      "   floor_area_sqm storey_range  resale_price  \n",
      "0            44.0     10 TO 12      232000.0  \n",
      "1            67.0     01 TO 03      250000.0  \n",
      "2            67.0     01 TO 03      262000.0  \n",
      "3            68.0     04 TO 06      265000.0  \n",
      "4            67.0     01 TO 03      265000.0  \n",
      "\n",
      "       month  year        town              full_address   nearest_stn  \\\n",
      "87370      1  2021  ANG MO KIO   170 ANG MO KIO AVENUE 4  Yio Chu Kang   \n",
      "87371      1  2021  ANG MO KIO   170 ANG MO KIO AVENUE 4  Yio Chu Kang   \n",
      "87372      1  2021  ANG MO KIO   331 ANG MO KIO AVENUE 1    Ang Mo Kio   \n",
      "87373      1  2021  ANG MO KIO  534 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
      "87374      1  2021  ANG MO KIO  561 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
      "\n",
      "       dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
      "87370             1.276775       8.339960           0.016807   \n",
      "87371             1.276775       8.339960           0.016807   \n",
      "87372             0.884872       6.981730           0.016807   \n",
      "87373             0.677246       8.333056           0.016807   \n",
      "87374             0.922047       8.009223           0.016807   \n",
      "\n",
      "       eigenvector_centrality         flat_model_type  remaining_lease_years  \\\n",
      "87370                0.002459        2 ROOM, Improved              64.083333   \n",
      "87371                0.002459        2 ROOM, Improved              64.083333   \n",
      "87372                0.006243  3 ROOM, New Generation              59.000000   \n",
      "87373                0.006243  3 ROOM, New Generation              58.166667   \n",
      "87374                0.006243  3 ROOM, New Generation              58.083333   \n",
      "\n",
      "       floor_area_sqm storey_range  resale_price  \n",
      "87370            45.0     01 TO 03      211000.0  \n",
      "87371            45.0     07 TO 09      225000.0  \n",
      "87372            68.0     04 TO 06      260000.0  \n",
      "87373            68.0     04 TO 06      265000.0  \n",
      "87374            68.0     01 TO 03      265000.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "train_df = df[df[\"year\"] <= 2020]\n",
    "test_df = df[df[\"year\"] == 2021]\n",
    "\n",
    "print(train_df.head(), end=\"\\n\\n\")\n",
    "\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\"resale_price\"],\n",
    "    continuous_cols=[\n",
    "        \"dist_to_nearest_stn\",\n",
    "        \"dist_to_dhoby\",\n",
    "        \"degree_centrality\",\n",
    "        \"eigenvector_centrality\",\n",
    "        \"remaining_lease_years\",\n",
    "        \"floor_area_sqm\",\n",
    "    ],\n",
    "    categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=1024,\n",
    "    max_epochs=50,\n",
    "    auto_lr_find=True,\n",
    ")\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\",\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"Adam\",\n",
    "    \n",
    ")\n",
    "\n",
    "model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">439</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m439\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m466\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">545</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m545\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">573</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m573\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:01\u001b[0m,\u001b[1;36m618\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/huruilizhen/Desktop/SC4001-Assignment-1/saved_models exists and is not empty.\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537b107d76434ded97bdae7e62f9b9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at /Users/huruilizhen/Desktop/SC4001-Assignment-1/.lr_find_fe1782b3-cdec-44e3-ab5a-b391d920763c.ckpt\n",
      "Restored all states from the checkpoint at /Users/huruilizhen/Desktop/SC4001-Assignment-1/.lr_find_fe1782b3-cdec-44e3-ab5a-b391d920763c.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:04</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5754399373371567</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:04\u001b[0m,\u001b[1;36m200\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.5754399373371567\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:04</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:04\u001b[0m,\u001b[1;36m202\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59a9dca214c44099c4137fcd1bb0993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">596</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:16\u001b[0m,\u001b[1;36m596\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">03:58:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m03:58:16\u001b[0m,\u001b[1;36m597\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/huruilizhen/Desktop/SC4001-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE error: 65112.12\n",
      "Test R2 value: 0.84\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "model.fit(train_df, test_df)\n",
    "preds = model.predict(test_df)\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "test_rmse = root_mean_squared_error(test_df[\"resale_price\"], preds)\n",
    "test_r2 = r2_score(test_df[\"resale_price\"], preds)\n",
    "\n",
    "print(f\"Test RMSE error: {test_rmse:.2f}\")\n",
    "print(f\"Test R2 value: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  year             town                full_address  \\\n",
      "90957       6  2021      BUKIT BATOK  288A BUKIT BATOK STREET 25   \n",
      "92405      11  2021      BUKIT MERAH            46 SENG POH ROAD   \n",
      "90608      12  2021           BISHAN       273B BISHAN STREET 24   \n",
      "93825       8  2021     CENTRAL AREA       4 TANJONG PAGAR PLAZA   \n",
      "93895      11  2021     CENTRAL AREA       3 TANJONG PAGAR PLAZA   \n",
      "92533      12  2021      BUKIT MERAH          2C BOON TIONG ROAD   \n",
      "112128     12  2021         TAMPINES      156 TAMPINES STREET 12   \n",
      "88081       8  2021       ANG MO KIO    310A ANG MO KIO AVENUE 1   \n",
      "92442      11  2021      BUKIT MERAH          127D KIM TIAN ROAD   \n",
      "90432       8  2021           BISHAN       275A BISHAN STREET 24   \n",
      "92340      10  2021      BUKIT MERAH            56 HAVELOCK ROAD   \n",
      "89770      10  2021            BEDOK           103 LENGKONG TIGA   \n",
      "98379      12  2021          HOUGANG        615 HOUGANG AVENUE 8   \n",
      "101237     11  2021  KALLANG/WHAMPOA            8 BOON KENG ROAD   \n",
      "90523      10  2021           BISHAN       273B BISHAN STREET 24   \n",
      "114254      9  2021        WOODLANDS      789 WOODLANDS AVENUE 6   \n",
      "91871       6  2021      BUKIT MERAH         17 TIONG BAHRU ROAD   \n",
      "90521      10  2021           BISHAN        237 BISHAN STREET 22   \n",
      "101236     11  2021  KALLANG/WHAMPOA            9 BOON KENG ROAD   \n",
      "91497       2  2021      BUKIT MERAH          21 LIM LIAK STREET   \n",
      "90382       7  2021           BISHAN        251 BISHAN STREET 22   \n",
      "90483       9  2021           BISHAN       273A BISHAN STREET 24   \n",
      "99334       3  2021      JURONG WEST    440 JURONG WEST AVENUE 1   \n",
      "90607      12  2021           BISHAN       273B BISHAN STREET 24   \n",
      "89366       7  2021            BEDOK           106 LENGKONG TIGA   \n",
      "\n",
      "          nearest_stn  dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
      "90957     Bukit Batok             1.292540      10.763777           0.016807   \n",
      "92405     Tiong Bahru             0.581977       2.309477           0.016807   \n",
      "90608          Bishan             0.776182       6.297489           0.033613   \n",
      "93825   Tanjong Pagar             0.451637       2.594828           0.016807   \n",
      "93895   Tanjong Pagar             0.490378       2.630876           0.016807   \n",
      "92533     Tiong Bahru             0.656363       1.982722           0.016807   \n",
      "112128       Tampines             0.370873      12.479752           0.033613   \n",
      "88081      Ang Mo Kio             0.860056       7.263401           0.016807   \n",
      "92442     Tiong Bahru             0.686789       2.664024           0.016807   \n",
      "90432          Bishan             0.827889       6.370404           0.033613   \n",
      "92340     Tiong Bahru             0.451387       2.128424           0.016807   \n",
      "89770       Kembangan             0.622824       7.791966           0.016807   \n",
      "98379         Hougang             0.899849       8.828235           0.016807   \n",
      "101237      Bendemeer             0.352251       2.587444           0.016807   \n",
      "90523          Bishan             0.776182       6.297489           0.033613   \n",
      "114254      Woodlands             1.915461      16.660245           0.016807   \n",
      "91871     Tiong Bahru             0.693391       2.058774           0.016807   \n",
      "90521          Bishan             0.947205       6.663943           0.033613   \n",
      "101236      Bendemeer             0.335875       2.535679           0.016807   \n",
      "91497     Tiong Bahru             0.592294       2.146843           0.016807   \n",
      "90382      Ang Mo Kio             1.081018       6.939944           0.016807   \n",
      "90483          Bishan             0.767244       6.327956           0.033613   \n",
      "99334        Lakeside             0.811590      14.849537           0.016807   \n",
      "90607          Bishan             0.776182       6.297489           0.033613   \n",
      "89366       Kembangan             0.591384       7.699265           0.016807   \n",
      "\n",
      "        eigenvector_centrality           flat_model_type  \\\n",
      "90957                 0.000217      EXECUTIVE, Apartment   \n",
      "92405                 0.047782          3 ROOM, Standard   \n",
      "90608                 0.015854              5 ROOM, DBSS   \n",
      "93825                 0.103876     5 ROOM, Adjoined flat   \n",
      "93895                 0.103876     5 ROOM, Adjoined flat   \n",
      "92533                 0.047782          5 ROOM, Improved   \n",
      "112128                0.000229     EXECUTIVE, Maisonette   \n",
      "88081                 0.006243          5 ROOM, Improved   \n",
      "92442                 0.047782          5 ROOM, Improved   \n",
      "90432                 0.015854              5 ROOM, DBSS   \n",
      "92340                 0.047782          5 ROOM, Improved   \n",
      "89770                 0.002799          5 ROOM, Improved   \n",
      "98379                 0.001507      EXECUTIVE, Apartment   \n",
      "101237                0.004414              5 ROOM, DBSS   \n",
      "90523                 0.015854              5 ROOM, DBSS   \n",
      "114254                0.000024     EXECUTIVE, Maisonette   \n",
      "91871                 0.047782          3 ROOM, Standard   \n",
      "90521                 0.015854          5 ROOM, Improved   \n",
      "101236                0.004414              5 ROOM, DBSS   \n",
      "91497                 0.047782          3 ROOM, Standard   \n",
      "90382                 0.006243          5 ROOM, Improved   \n",
      "90483                 0.015854              5 ROOM, DBSS   \n",
      "99334                 0.000085  EXECUTIVE, Adjoined flat   \n",
      "90607                 0.015854              5 ROOM, DBSS   \n",
      "89366                 0.002799     EXECUTIVE, Maisonette   \n",
      "\n",
      "        remaining_lease_years  floor_area_sqm storey_range  resale_price  \n",
      "90957               75.583333           144.0     10 TO 12      968000.0  \n",
      "92405               50.166667            88.0     01 TO 03      780000.0  \n",
      "90608               88.833333           120.0     37 TO 39     1360000.0  \n",
      "93825               54.583333           118.0     16 TO 18      938000.0  \n",
      "93895               54.250000           139.0     07 TO 09      958000.0  \n",
      "92533               78.083333           115.0     28 TO 30     1130000.0  \n",
      "112128              61.750000           148.0     01 TO 03      998000.0  \n",
      "88081               90.166667           121.0     28 TO 30     1100000.0  \n",
      "92442               90.333333           113.0     16 TO 18     1165000.0  \n",
      "90432               88.916667           120.0     25 TO 27     1280000.0  \n",
      "92340               90.750000           114.0     34 TO 36     1245000.0  \n",
      "89770               66.333333           126.0     10 TO 12      868000.0  \n",
      "98379               63.666667           142.0     04 TO 06      873000.0  \n",
      "101237              88.250000           119.0     40 TO 42     1268000.0  \n",
      "90523               88.916667           120.0     22 TO 24     1260000.0  \n",
      "114254              75.083333           141.0     10 TO 12      800000.0  \n",
      "91871               50.583333            88.0     01 TO 03      680888.0  \n",
      "90521               69.583333           121.0     07 TO 09      988000.0  \n",
      "101236              88.250000           119.0     34 TO 36     1230000.0  \n",
      "91497               51.000000            75.0     01 TO 03      618000.0  \n",
      "90382               70.166667           121.0     10 TO 12      945000.0  \n",
      "90483               89.000000           120.0     37 TO 39     1295000.0  \n",
      "99334               63.166667           148.0     04 TO 06      743000.0  \n",
      "90607               88.750000           120.0     10 TO 12     1208000.0  \n",
      "89366               66.750000           146.0     04 TO 06      968000.0  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "test_errors = (preds[\"resale_price_prediction\"] - test_df[\"resale_price\"]).abs()\n",
    "top_25_test_errors = test_errors.nlargest(25)\n",
    "print(test_df.loc[top_25_test_errors.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q2 (10 marks)\n",
    "---\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data（validation set is not required here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 hidden layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 60 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q3 (10 marks)\n",
    "---\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, use the train set (year 2020 and before) and test set (year 2021) following the splits in Question B1 (validation set is not required here). To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Standardise the features via **StandardScaler** (fit to training set, then transform all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Input x Gradients, Integrated Gradients, DeepLift, GradientSHAP, Feature Ablation. To avoid long running time, you can limit the analysis to the first 1000 samples in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum to build up your understanding of the difference of various explainability algorithms. Based on your plot, identify the three most important features for regression. Explain how each of these features influences the regression outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q4 (10 marks)\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Did model degradation occur for the deep learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2020 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
